// Prisma schema for AI Service Vector Database
// Handles all vector storage and semantic search operations

generator client {
  provider        = "prisma-client-js"
  previewFeatures = ["postgresqlExtensions"]
}

datasource db {
  provider   = "postgresql"
  url        = env("DATABASE_URL")
  extensions = [pgvector(map: "vector")]
}

// ==================== KNOWLEDGE VECTORS ====================
// Stores embeddings for knowledge base items
// Source of truth for vector search on knowledge

model knowledge_vectors {
  id                String   @id // Same ID as dashboard.knowledge_base
  village_id         String?
  title             String
  content           String   @db.Text
  category          String
  keywords          String[]
  
  // Vector embedding
  embedding         Unsupported("vector(768)")
  embedding_model   String   @default("gemini-embedding-001")
  
  // Quality metrics (synced from dashboard or computed here)
  quality_score     Float    @default(1.0)
  usage_count       Int      @default(0)
  retrieval_count   Int      @default(0)
  last_retrieved    DateTime?
  
  // Timestamps
  created_at        DateTime @default(now())
  updated_at        DateTime @updatedAt
  
  @@index([category])
  @@index([village_id])
  @@index([quality_score])
}

// ==================== DOCUMENT VECTORS ====================
// Stores embeddings for document chunks
// Each document can have multiple chunks

model document_vectors {
  id                String   @id @default(cuid())
  document_id       String   // Reference to dashboard.knowledge_documents
  village_id         String?
  chunk_index       Int
  content           String   @db.Text
  
  // Document metadata (denormalized for search)
  document_title    String?
  category          String?
  page_number       Int?
  section_title     String?
  
  // Vector embedding
  embedding         Unsupported("vector(768)")
  embedding_model   String   @default("gemini-embedding-001")
  
  // Timestamps
  created_at        DateTime @default(now())
  
  @@unique([document_id, chunk_index])
  @@index([document_id])
  @@index([village_id])
  @@index([category])
}

// ==================== EMBEDDING JOBS ====================
// Track embedding generation jobs for async processing

model embedding_jobs {
  id            String   @id @default(cuid())
  type          String   // "knowledge" | "document"
  target_id     String   // ID of knowledge/document
  status        String   @default("pending") // pending, processing, completed, failed
  error_message String?  @db.Text
  retry_count   Int      @default(0)
  priority      Int      @default(0)
  
  created_at    DateTime @default(now())
  started_at    DateTime?
  completed_at  DateTime?
  
  @@index([status])
  @@index([priority])
}

// ==================== AI TOKEN USAGE ====================
// Tracks actual token usage from Gemini API responses (usageMetadata)
// Stored per-call for granular analytics

model ai_token_usage {
  id              String   @id @default(cuid())
  
  // Model info
  model           String   // e.g. "gemini-2.5-flash", "gemini-2.0-flash-lite"
  
  // Token counts (from Gemini usageMetadata)
  input_tokens    Int      // promptTokenCount
  output_tokens   Int      // candidatesTokenCount
  total_tokens    Int      // totalTokenCount
  
  // Cost in USD (calculated from pricing table)
  cost_usd        Float    @default(0)
  
  // Call classification
  layer_type      String   // "full_nlu" | "micro_nlu" | "embedding" | "rag_expand"
  call_type       String   // "main_chat" | "anti_hallucination_retry" | "complaint_type_match" | "service_slug_match" | "rag_query_expand" | "confirmation_classify" | "farewell_classify" | "greeting_classify" | "embedding_single" | "embedding_batch"
  
  // Tenant & user context
  village_id      String?
  wa_user_id      String?
  session_id      String?  // webchat session or WA user id
  channel         String?  // "whatsapp" | "webchat"
  
  // LLM response context
  intent          String?  // The detected intent (for main_chat calls)
  success         Boolean  @default(true)
  duration_ms     Int?     // How long the LLM call took
  
  // API Key source tracking
  key_source      String?  // "byok" | "env" | null (for older records)
  key_id          String?  // BYOK key ID if applicable
  key_tier        String?  // "free" | "tier1" | "tier2" | "env"
  
  created_at      DateTime @default(now())
  
  @@index([model])
  @@index([village_id])
  @@index([layer_type])
  @@index([call_type])
  @@index([created_at])
  @@index([village_id, created_at])
  @@index([model, created_at])
  @@index([channel, created_at])
  @@index([key_source])
}

// ==================== CONVERSATION SESSIONS (Temuan 7) ====================
// Persists critical in-memory conversation state to survive restarts
// Fire-and-forget writes â€” stale data is acceptable, lost data is not

model conversation_sessions {
  id              String   @id @default(cuid())
  wa_user_id      String
  session_key     String   // e.g. "pendingComplaintData", "pendingAddressConfirmation"
  state_json      String   @db.Text // JSON-serialized state
  expires_at      DateTime // Auto-cleanup expired sessions
  created_at      DateTime @default(now())
  updated_at      DateTime @updatedAt

  @@unique([wa_user_id, session_key])
  @@index([wa_user_id])
  @@index([expires_at])
}

// ==================== RATE LIMIT BLACKLIST (Temuan 8) ====================
// Persists rate limiter blacklist entries so they survive service restarts

model rate_limit_blacklist {
  id              String   @id @default(cuid())
  wa_user_id      String   @unique
  reason          String
  blocked_at      DateTime @default(now())
  expires_at      DateTime? // null = permanent
  violation_count Int      @default(0)
  created_at      DateTime @default(now())
  updated_at      DateTime @updatedAt

  @@index([wa_user_id])
  @@index([expires_at])
}
